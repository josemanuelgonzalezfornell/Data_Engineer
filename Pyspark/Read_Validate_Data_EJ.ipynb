{"cells":[{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"54c15bba-8182-4aa2-a923-74e3ba3e0f42","showTitle":false,"title":""}},"source":["## Next let's start by reading a basic csv dataset\n","\n","Download the pga_tour_historical dataset that is attached to this lecture and save it whatever folder you want, then read it in. \n","\n","**Data Source:** https://www.kaggle.com/bradklassen/pga-tour-20102018-data\n","\n","Rememer to try letting Spark infer the header and infer the Schema types!"]},{"cell_type":"code","execution_count":25,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"8052da17-1a42-4fe0-bde8-f8f3ef872e68","showTitle":false,"title":""}},"outputs":[],"source":["import pyspark\n","from pyspark.sql import SparkSession\n","from pyspark.sql.functions import *"]},{"cell_type":"code","execution_count":6,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"b3050d53-40e8-42e6-b063-9e677395f104","showTitle":false,"title":""}},"outputs":[],"source":["path = \"data/pga_tour_historical.csv\"\n","spark = SparkSession.builder.appName(\"Python Spark SQL basic example\").getOrCreate()"]},{"cell_type":"code","execution_count":7,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"97abe3f3-53cb-41fd-a661-ab2761687cdc","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://192.168.100.26:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.4.0</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Python Spark SQL basic example</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x104ecfe50>"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["spark"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"e198e620-3db9-4792-8d27-61e9c8dcce22","showTitle":false,"title":""}},"source":["## 1. View first 5 lines of dataframe\n","First generate a view of the first 5 lines of the dataframe to get an idea of what is inside. We went over two ways of doing this... see if you can remember BOTH ways."]},{"cell_type":"code","execution_count":12,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"1b83e97a-51a1-4a94-ae46-7538346bafb6","showTitle":false,"title":""}},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Player Name</th>\n","      <th>Season</th>\n","      <th>Statistic</th>\n","      <th>Variable</th>\n","      <th>Value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Robert Garrigus</td>\n","      <td>2010</td>\n","      <td>Driving Distance</td>\n","      <td>Driving Distance - (ROUNDS)</td>\n","      <td>71</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Bubba Watson</td>\n","      <td>2010</td>\n","      <td>Driving Distance</td>\n","      <td>Driving Distance - (ROUNDS)</td>\n","      <td>77</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Dustin Johnson</td>\n","      <td>2010</td>\n","      <td>Driving Distance</td>\n","      <td>Driving Distance - (ROUNDS)</td>\n","      <td>83</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Brett Wetterich</td>\n","      <td>2010</td>\n","      <td>Driving Distance</td>\n","      <td>Driving Distance - (ROUNDS)</td>\n","      <td>54</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>J.B. Holmes</td>\n","      <td>2010</td>\n","      <td>Driving Distance</td>\n","      <td>Driving Distance - (ROUNDS)</td>\n","      <td>100</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Player Name  Season         Statistic                     Variable   \n","0  Robert Garrigus    2010  Driving Distance  Driving Distance - (ROUNDS)  \\\n","1     Bubba Watson    2010  Driving Distance  Driving Distance - (ROUNDS)   \n","2   Dustin Johnson    2010  Driving Distance  Driving Distance - (ROUNDS)   \n","3  Brett Wetterich    2010  Driving Distance  Driving Distance - (ROUNDS)   \n","4      J.B. Holmes    2010  Driving Distance  Driving Distance - (ROUNDS)   \n","\n","  Value  \n","0    71  \n","1    77  \n","2    83  \n","3    54  \n","4   100  "]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["pga = spark.read.csv(path, inferSchema=True, header = True)\n","pga.limit(5).toPandas()"]},{"cell_type":"code","execution_count":13,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"facb43c7-8b5c-45f2-94b4-0733540029fb","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------+------+----------------+--------------------+-----+\n","|    Player Name|Season|       Statistic|            Variable|Value|\n","+---------------+------+----------------+--------------------+-----+\n","|Robert Garrigus|  2010|Driving Distance|Driving Distance ...|   71|\n","|   Bubba Watson|  2010|Driving Distance|Driving Distance ...|   77|\n","| Dustin Johnson|  2010|Driving Distance|Driving Distance ...|   83|\n","|Brett Wetterich|  2010|Driving Distance|Driving Distance ...|   54|\n","|    J.B. Holmes|  2010|Driving Distance|Driving Distance ...|  100|\n","+---------------+------+----------------+--------------------+-----+\n","\n"]}],"source":["pga.limit(5).show()"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"8f1334cc-2dc7-43f0-add5-c49969a4c35c","showTitle":false,"title":""}},"source":["## 2. Print the schema details\n","\n","Now print the details of the dataframes schema that Spark infered to ensure that it was infered correctly. Sometimes it is not infered correctly, so we need to watch out!"]},{"cell_type":"code","execution_count":21,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"ff62486f-fb18-483f-bce2-99e393d42776","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- Player Name: string (nullable = true)\n"," |-- Season: integer (nullable = true)\n"," |-- Statistic: string (nullable = true)\n"," |-- Variable: string (nullable = true)\n"," |-- Value: string (nullable = true)\n","\n","None\n","------------------------\n","['Player Name', 'Season', 'Statistic', 'Variable', 'Value']\n","------------------------\n"]},{"data":{"text/plain":["DataFrame[summary: string, Player Name: string, Season: string, Statistic: string, Variable: string, Value: string]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["print(pga.printSchema())\n","print(\"------------------------\")\n","print(pga.columns)\n","print(\"------------------------\")\n","pga.describe()"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"d0c7d69e-973d-415f-9bbc-717adf51a253","showTitle":false,"title":""}},"source":["## 3. Edit the schema during the read in\n","\n","We can see from the output above that Spark did not correctly infer that the \"value\" column was an integer value. Let's try specifying the schema this time to let spark know what the schema should be.\n","\n","Here is a link to see a list of PySpark data types in case you need it (also attached to the lecture): \n","https://spark.apache.org/docs/latest/sql-ref-datatypes.html"]},{"cell_type":"code","execution_count":22,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"c145d7f9-f8a9-46ca-9478-41d4d84cfbce","showTitle":false,"title":""}},"outputs":[],"source":["from pyspark.sql.types import *"]},{"cell_type":"code","execution_count":50,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"4cd0581a-372f-4073-8485-81a2e589ba92","showTitle":false,"title":""}},"outputs":[],"source":["data_schema = [StructField(\"Player\", StringType(), True),\n","               StructField(\"Season\", IntegerType(), True),\n","               StructField(\"Statistic\", StringType(), True),\n","               StructField(\"Variable\", StringType(), True),\n","               StructField(\"Value\", IntegerType(), True),\n","               ]"]},{"cell_type":"code","execution_count":51,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"e8c96e39-309c-481d-9ca5-366ab80bf685","showTitle":false,"title":""}},"outputs":[],"source":["final_struc = StructType(fields = data_schema)\n","pga = spark.read.json(\"data/pga_tour_historical.csv\", schema =final_struc)"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- Player: string (nullable = true)\n"," |-- Season: integer (nullable = true)\n"," |-- Statistic: string (nullable = true)\n"," |-- Variable: string (nullable = true)\n"," |-- Value: integer (nullable = true)\n","\n"]}],"source":["pga.printSchema()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"7a2df2be-064b-43a1-a320-d72d77e80670","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- Player Name: string (nullable = true)\n"," |-- Season: integer (nullable = true)\n"," |-- Statistic: string (nullable = true)\n"," |-- Variable: string (nullable = true)\n"," |-- Value: integer (nullable = true)\n","\n"]}],"source":[]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"683801e4-7d8b-46b2-9b2f-63bf05b86297","showTitle":false,"title":""}},"source":["## 4. Generate summary statistics for only one variable\n","\n","See if you can generate summary statistics for only the \"Value\" column using the .describe function\n","\n","(count, mean, stddev, min, max)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"9e85bcec-1743-4609-ac37-8672ae53500a","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+------------------+\n","|summary|             Value|\n","+-------+------------------+\n","|  count|           1657247|\n","|   mean|12494.388998743096|\n","| stddev| 157274.7567357075|\n","|    min|              -178|\n","|    max|           3564954|\n","+-------+------------------+\n","\n"]}],"source":[]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"dee298b2-3ac4-424b-8d39-3baa947bfbd6","showTitle":false,"title":""}},"source":["## 5. Generate summary statistics for TWO variables\n","Now try to generate ONLY the count min and max for BOTH the \"Value\" and \"Season\" variable using the select. You can't use the .describe function for this one but see if you can remember which function you CAN use."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"ce204b85-2918-4f18-b0ac-9a5ecb56708e","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+------------------+------------------+\n","|summary|             Value|            Season|\n","+-------+------------------+------------------+\n","|  count|           1657247|           2740403|\n","|   mean|12494.388998743096| 2013.973479083186|\n","| stddev| 157274.7567357075|2.6070501155146517|\n","|    min|              -178|              2010|\n","|    max|           3564954|              2018|\n","+-------+------------------+------------------+\n","\n"]}],"source":[]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"204e767a-b65e-4807-a6b4-5a36d72c9d39","showTitle":false,"title":""}},"source":["## 10. Create your own dataframe\n","\n","Try creating your own dataframe below using PySparks *.createDataFrame* function. See if you can make one that contains 4 variables and at least 3 rows. \n","\n","Let's see how creative you can get on the content of the dataframe :)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"d48cc484-0945-4f84-869c-864ffe5050e0","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Number</th>\n","      <th>Position</th>\n","      <th>age</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Gignac</td>\n","      <td>10</td>\n","      <td>Dl</td>\n","      <td>38</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Carioca</td>\n","      <td>5</td>\n","      <td>MC</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Nahuel</td>\n","      <td>1</td>\n","      <td>PO</td>\n","      <td>38</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Samir</td>\n","      <td>3</td>\n","      <td>DFC</td>\n","      <td>28</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Number</th>\n      <th>Position</th>\n      <th>age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Gignac</td>\n      <td>10</td>\n      <td>Dl</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Carioca</td>\n      <td>5</td>\n      <td>MC</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Nahuel</td>\n      <td>1</td>\n      <td>PO</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Samir</td>\n      <td>3</td>\n      <td>DFC</td>\n      <td>28</td>\n    </tr>\n  </tbody>\n</table>\n</div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"textData":null,"type":"htmlSandbox"}},"output_type":"display_data"}],"source":[]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"999b01ba-028e-468c-9ba6-edb5e148c0b3","showTitle":false,"title":""}},"source":["## We're done! Great job!"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"Read_Validate_Data_EJ","widgets":{}},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"}},"nbformat":4,"nbformat_minor":0}
